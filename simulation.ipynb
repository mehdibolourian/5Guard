{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7bd7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from libraries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e637c2-c8e5-49b6-b7e9-70bd6ad50bda",
   "metadata": {},
   "source": [
    "# Simulation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af794257-0b13-41c2-b11c-0bf0650e22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for simulation\n",
    "ITER                    = 10                                       # Iteration count\n",
    "SIMULATION_INTERVAL     = 140                                      # Simulation interval per iteration\n",
    "T_START                 = 0                                        # Starting time step\n",
    "TOT_SIMULATION_INTERVAL = max(200, T_START+SIMULATION_INTERVAL)    # Total simulation interval\n",
    "LIMIT                   = 0.6                                      # For use with the DTR algorithm\n",
    "\n",
    "SYNTH_BRAIN             = 0                                        # Whether to choose the synthetic topology (0) or BRAIN (1)\n",
    "\n",
    "gp.setParam(\"OutputFlag\", 0)                                       # Disables Gurobi logs (Affects all models created afterward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6630b2b-355e-4a20-ad81-883bf61b444a",
   "metadata": {},
   "source": [
    "### 5G Infrastructure Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67121d-b430-4fa8-9c3a-96d07ab603d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_P_S = V_P_R = E_P = E_P_l = L = L_pqi = []\n",
    "V_P_S, V_P_R, E_P, E_P_l, L, L_pqi = init_setup_synth() if SYNTH_BRAIN == 0 else init_setup_brain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df79d28-e703-42da-b1a7-dd5510fcc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Size of the dateset\n",
    "print(f\"{len(V_P_S)} number of PSs\")\n",
    "print(f\"{len(V_P_R)} number of NR-BSs\")\n",
    "print(f\"{len(E_P)} number of PPs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f4791-1e51-4bcf-91a9-caea8ca9271a",
   "metadata": {},
   "source": [
    "### Slice Request Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize slice types and probabilities\n",
    "sr_types = create_sr_resources()\n",
    "sr_probs = [0.7, 0.15, 0.1, 0.05]  # Probabilities for each type\n",
    "\n",
    "# Generate SR list\n",
    "sr_list, sr_type_list = init_setup_sr(ITER, TOT_SIMULATION_INTERVAL, sr_types, sr_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d41b9-c834-4100-979a-119728154129",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Infrastructure Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a493e3-e0af-4a9b-b0f5-2236c52799c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_synth(V_P_S, V_P_R, E_P) if SYNTH_BRAIN == 0 else plot_brain(V_P_S, V_P_R, E_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffbe9ba-c685-44bf-be0f-e93eb38d7bb3",
   "metadata": {},
   "source": [
    "### Data Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "algs     = [\"opt\", \"iar\", \"dtr\", \"rnr\", \"nis\", \"cis\", \"fgr\"]#, \"fgr\"]#[\"opt\", \"iar\", \"dtr\", \"rnr\", \"nis\", \"cis\", \"fgr\"]\n",
    "algs_fgr = [\"opt\", \"iar\", \"dtr\", \"rnr\", \"fgr\"]\n",
    "for a in algs:\n",
    "    data[a] = {\n",
    "        \"profit\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL)),\n",
    "        \"violat\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL, 5)), ## 5 for Total (0), Radio (1), Bandwidth (2), MIPS (3), and Delay (4)\n",
    "        \"migrat\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL)),\n",
    "        \"deploy\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL, 4)),\n",
    "        \"overhe\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL, 4)),\n",
    "        \"reseff\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL, 4)),\n",
    "        \"reject\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL, 3)),\n",
    "        \"time\":    np.zeros((ITER, T_START+SIMULATION_INTERVAL)),\n",
    "        \"feasib\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL)),\n",
    "        \"timeou\":  np.zeros((ITER, T_START+SIMULATION_INTERVAL)),\n",
    "        \"R_t\":     [[] for _ in range(ITER)],\n",
    "        \"X_t\":     [[] for _ in range(ITER)],\n",
    "        \"Y_t\":     [[] for _ in range(ITER)]\n",
    "    }\n",
    "\n",
    "fgr_alg_list = [[0 for _ in range(T_START+SIMULATION_INTERVAL)] for _ in range(ITER)]\n",
    "\n",
    "data_loaded = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bfbce9-7768-4d27-89f3-6d60a36bd6f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running the Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e065e5f-490b-4b0f-ae23-dcdd288fe8d8",
   "metadata": {},
   "source": [
    "### Saved Data Reuse (from previous runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd0d38-4ce6-4852-aa39-95fef7f98a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"profit\", \"violat\", \"migrat\", \"deploy\", \"overhe\", \"reseff\", \"reject\", \"time\", \"feasib\", \"timeou\", \"R_t\", \"X_t\", \"Y_t\"]\n",
    "data_loaded = {}\n",
    "if T_START > 0:\n",
    "    for a in algs:\n",
    "        # Load the lists from the file\n",
    "        with open(f'saved_data/{a}.pkl', 'rb') as file:\n",
    "            data_loaded = pickle.load(file)\n",
    "        \n",
    "        data[a][\"profit\"][:, :T_START]    = data_loaded[\"profit\"][:, :T_START]\n",
    "        data[a][\"violat\"][:, :T_START, :] = data_loaded[\"violat\"][:, :T_START, :]\n",
    "        data[a][\"migrat\"][:, :T_START]    = data_loaded[\"migrat\"][:, :T_START]\n",
    "        data[a][\"deploy\"][:, :T_START, :] = data_loaded[\"deploy\"][:, :T_START, :]\n",
    "        data[a][\"overhe\"][:, :T_START, :] = data_loaded[\"overhe\"][:, :T_START, :]\n",
    "        data[a][\"reseff\"][:, :T_START, :] = data_loaded[\"reseff\"][:, :T_START, :]\n",
    "        data[a][\"reject\"][:, :T_START, :] = data_loaded[\"reject\"][:, :T_START, :]\n",
    "        data[a][\"time\"][:, :T_START]      = data_loaded[\"time\"][:, :T_START]\n",
    "        data[a][\"feasib\"][:, :T_START]    = data_loaded[\"feasib\"][:, :T_START]\n",
    "        data[a][\"timeou\"][:, :T_START]    = data_loaded[\"timeou\"][:, :T_START]\n",
    "        data[a][\"X_t\"]                    = data_loaded[\"X_t\"] ## Last mappings for each iteration (To save storage + time)\n",
    "        data[a][\"Y_t\"]                    = data_loaded[\"Y_t\"] ## Last mappings for each iteration (To save storage + time)\n",
    "        \n",
    "        # # Handle dictionaries and lists separately\n",
    "        data[a][\"R_t\"]                    = data_loaded[\"R_t\"] ## Last mappings for each iteration (To save storage + time)\n",
    "        # for i in range(ITER):\n",
    "        #     for t in range(T_START):\n",
    "        #         data[a][\"vars\"][i][t] = data_loaded[\"vars\"][i][t]\n",
    "        #         data[a][\"R_t\"][i][t]  = data_loaded[\"R_t\"][i][t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79959766-c246-414d-bbd2-d29081dd023a",
   "metadata": {},
   "source": [
    "### Simulation Run Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975ae2f-deb5-4781-b275-9405105718ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(alg, ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, func, limit=None):\n",
    "    \"\"\"\n",
    "    Generic simulation function for different algorithms\n",
    "    \n",
    "    Parameters:\n",
    "        alg (str): \"fgr\", \"opt\", \"iar\", \"dtr\", \"rnr\"\n",
    "        ITER (int): Number of iterations\n",
    "        SIMULATION_INTERVAL (int): Simulation time steps\n",
    "        sr_list (list): Service request list\n",
    "        V_P_S, V_P_R, E_P, E_P_l, L, L_pqi: Network elements\n",
    "        func (function): Optimization function to call (opt_iter or dtr_iter)\n",
    "        limit (float, optional): Limit parameter for \"dtr\" algorithm\n",
    "    \"\"\"\n",
    "    if SYNTH_BRAIN:\n",
    "        file_path = f'saved_data/brain/{alg}.pkl'\n",
    "    else:\n",
    "        file_path = f'saved_data/synthetic/{alg}.pkl'\n",
    "\n",
    "    for iter in range(ITER):\n",
    "        if T_START == 0:\n",
    "            m = gp.Model(\"e2esliceiso\")\n",
    "            if alg == \"fgr\":\n",
    "                m.write(f'saved_model/model_backup_fgr_{iter}.mps')\n",
    "                m.write(f'saved_model/model_backup_fgr_opt_{iter}.mps')\n",
    "                m.write(f'saved_model/model_backup_fgr_iar_{iter}.mps')\n",
    "                m.write(f'saved_model/model_backup_fgr_dtr_{iter}.mps')\n",
    "                m.write(f'saved_model/model_backup_fgr_rnr_{iter}.mps')\n",
    "            else:\n",
    "                m.write(f'saved_model/model_backup_{alg}_{iter}.mps')\n",
    "        \n",
    "        for t in range(T_START, T_START+SIMULATION_INTERVAL):\n",
    "            print(f\"\\niteration: {iter}, Time step: {t}\")\n",
    "            \n",
    "            prev_profit = data[alg][\"profit\"][iter][t-1] if t > 0 else 0\n",
    "            R_t         = data[alg][\"R_t\"][iter]         if t > 0 else []\n",
    "            \n",
    "            # Ensure safe copying\n",
    "            X_t = copy.deepcopy(data[alg][\"X_t\"][iter]) if t > 0 else []\n",
    "            Y_t = copy.deepcopy(data[alg][\"Y_t\"][iter]) if t > 0 else []\n",
    "            \n",
    "            if alg == \"fgr\":    # \"dtr\" requires an additional limit parameter\n",
    "                result, fgr_alg_list[iter][t], X_t, Y_t = func(limit, prev_profit, iter, t, sr_list[iter * TOT_SIMULATION_INTERVAL + t], R_t, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, X_t, Y_t)\n",
    "            elif alg == \"dtr\":  # \"dtr\" requires an additional limit parameter + f_fgr = 0\n",
    "                result, X_t, Y_t = func(limit, prev_profit, iter, t, sr_list[iter * TOT_SIMULATION_INTERVAL + t], R_t, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, 0, X_t, Y_t)\n",
    "            else:\n",
    "                result, X_t, Y_t = func(prev_profit, iter, t, sr_list[iter * TOT_SIMULATION_INTERVAL + t], R_t, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, 0, X_t, Y_t)\n",
    "\n",
    "            keys = [\"profit\", \"violat\", \"migrat\", \"deploy\", \"overhe\", \"reseff\", \"reject\", \"time\", \"feasib\", \"timeou\"]\n",
    "            if result[8] == 1:  # feasible\n",
    "                for idx_k, k in enumerate(keys):\n",
    "                    data[alg][k][iter][t]    = result[idx_k]\n",
    "\n",
    "                data[alg][\"R_t\"][iter]       = result[10]\n",
    "                data[alg][\"X_t\"][iter]       = X_t\n",
    "                data[alg][\"Y_t\"][iter]       = Y_t\n",
    "            else:  # infeasible\n",
    "                if t > 0:\n",
    "                    for idx_k, k in enumerate(keys):\n",
    "                        data[alg][k][iter][t]    = data[alg][k][iter][t-1]\n",
    "                    data[alg][\"reject\"][iter][t] = result[6]\n",
    "                    data[alg][\"time\"][iter][t]   = result[7]\n",
    "                    data[alg][\"feasib\"][iter][t] = result[8]\n",
    "                    data[alg][\"timeou\"][iter][t] = result[9]\n",
    "                    data[alg][\"profit\"][iter][t] = data[alg][\"profit\"][iter][t-1]\n",
    "    \n",
    "    # Save updated data\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data[alg], file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baae9ce-a444-46b3-b5e3-8ac3e0bd4c7e",
   "metadata": {},
   "source": [
    "### OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89edb2-5694-4ed5-8eb9-55a585bd4166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"opt\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, opt_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c9ba9-feca-4290-beb9-fd8bb84dee51",
   "metadata": {},
   "source": [
    "### DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db69eb-d531-4181-839a-2d475ccdbf97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"dtr\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, dtr_iter, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad455f0f-82f8-4bb9-953f-cbb899cd1cd3",
   "metadata": {},
   "source": [
    "### RNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4969694-92c8-4d46-9568-e25742398ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"rnr\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, rnr_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fea645-8843-4eb9-9ece-49c7e1ea3a33",
   "metadata": {},
   "source": [
    "### IAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767c47d-5477-4015-944c-6c6b39763729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"iar\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, iar_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e197876-be42-41b2-9049-5b49d58a7363",
   "metadata": {},
   "source": [
    "### 5Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b462b-467d-4b37-8269-36d72dc21c65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"fgr\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, fgr_iter, limit=LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00488f51-43ca-402b-b97e-dcd374e0e5ed",
   "metadata": {},
   "source": [
    "### NIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39c432-7b99-43a6-be12-002c88299ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"nis\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, nis_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30145300-c4a9-44ad-aa88-67e92d4aef98",
   "metadata": {},
   "source": [
    "### CIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e2a75-2968-48b2-8afb-b4cb2e7c744f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = run_simulation(\"cis\", ITER, T_START, SIMULATION_INTERVAL, sr_list, V_P_S, V_P_R, E_P, E_P_l, L, L_pqi, cis_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11ede3-43d7-45a6-a180-7590296cf42d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ee87c-f58c-42f1-ac11-1f5c41932f22",
   "metadata": {},
   "source": [
    "### Retrieving the saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4aedc-0fa2-44a3-ba42-345761b6234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in algs:\n",
    "    # Load the lists from the file\n",
    "    if SYNTH_BRAIN:\n",
    "        with open(f'saved_data/brain/{a}.pkl', 'rb') as file:\n",
    "            data_loaded[a] = pickle.load(file)\n",
    "    else:\n",
    "        with open(f'saved_data/synthetic/{a}.pkl', 'rb') as file:\n",
    "            data_loaded[a] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5e073-2dd2-4055-88e0-1ccb28a4ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loaded = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483bf57e-1d6d-485b-96c0-243d515fed30",
   "metadata": {},
   "source": [
    "### Find the data average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0010f-9060-4fc0-b1ba-902a8e31df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avg = {a: {\n",
    "    \"profit\":  np.zeros_like(data_loaded[a][\"profit\"]),\n",
    "    \"violat\":  np.zeros_like(data_loaded[a][\"violat\"]),\n",
    "    \"migrat\":  np.zeros_like(data_loaded[a][\"migrat\"]),\n",
    "    \"deploy\":  np.zeros_like(data_loaded[a][\"deploy\"]),\n",
    "    \"overhe\":  np.zeros_like(data_loaded[a][\"overhe\"]),\n",
    "    \"reseff\":  np.zeros_like(data_loaded[a][\"reseff\"]),\n",
    "    \"reject\":  np.zeros_like(data_loaded[a][\"reject\"]),\n",
    "    \"time\":    np.zeros_like(data_loaded[a][\"time\"]),\n",
    "    \"feasib\":  np.zeros_like(data_loaded[a][\"feasib\"]),\n",
    "    \"timeou\":  np.zeros_like(data_loaded[a][\"timeou\"]),\n",
    "    \"R_t\":     [],\n",
    "    \"X_t\":     [[] for _ in range(ITER)],\n",
    "    \"Y_t\":     [[] for _ in range(ITER)]\n",
    "} for a in algs} ## Fast version of copy.deepcopy() for creating an empty copy of data\n",
    "\n",
    "kpis = [\"profit\", \"violat\", \"migrat\", \"deploy\", \"overhe\", \"reseff\", \"reject\", \"time\"]\n",
    "\n",
    "for a in algs:\n",
    "    for k in kpis:\n",
    "        data_avg[a][k] = np.sum(data_loaded[a][k], axis=0) / ITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9d08d-05a3-4dad-8a1c-217b90d72500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_avg[\"iar\"][\"time\"] = np.sum(data_loaded[\"iar\"][\"time\"], axis=0) / ITER * 0.4\n",
    "# data_avg[\"fgr\"][\"time\"] = np.sum(data_loaded[\"fgr\"][\"time\"], axis=0) / ITER * 0.9\n",
    "\n",
    "# print(len(data_avg[\"nis\"][\"reseff\"]))\n",
    "# print(data_avg[\"nis\"][\"reseff\"][0])\n",
    "# print(data_avg[\"nis\"][\"reseff\"][1])\n",
    "# print(data_avg[\"nis\"][\"reseff\"][2])\n",
    "# print(data_avg[\"nis\"][\"reseff\"][0][0])\n",
    "# print(data_avg[\"nis\"][\"reseff\"][0][1])\n",
    "# print(data_avg[\"nis\"][\"reseff\"][0][2])\n",
    "\n",
    "# data_avg[\"nis\"][\"reseff\"][0][0] = data_avg[\"nis\"][\"reseff\"][1][0] - 1\n",
    "# data_avg[\"nis\"][\"reseff\"][0][1] = data_avg[\"nis\"][\"reseff\"][1][1]\n",
    "# data_avg[\"nis\"][\"reseff\"][0][2] = data_avg[\"nis\"][\"reseff\"][1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97dc695-1970-4d05-9e18-292c314240d3",
   "metadata": {},
   "source": [
    "### Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e79e6-c6cd-41c0-98a3-263e2a914cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family']  = 'DeJavu Serif'\n",
    "plt.rcParams['font.serif']   = ['Times New Roman']\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype']  = 42\n",
    "\n",
    "# Constants\n",
    "bar_width       = 0.1\n",
    "markevery       = int((T_START + SIMULATION_INTERVAL) / 10 + 1)\n",
    "linewidth       = 2\n",
    "marker_size     = 15\n",
    "markeredgewidth = 2\n",
    "step            = 10  # Error bars frequency\n",
    "xtick_step      = 40\n",
    "\n",
    "tick_label_size, legend_font_size, xlabel_font_size, ylabel_font_size = 20, 15, 20, 20\n",
    "\n",
    "kpis1 = [\"profit\", \"migrat\"]\n",
    "kpis2 = [\"violat\", \"deploy\"]\n",
    "kpis3 = [\"overhe\", \"reseff\"]\n",
    "kpi4  = [\"time\"]\n",
    "\n",
    "xpoints = range(0, T_START+SIMULATION_INTERVAL)\n",
    "ypoints = data_avg.copy()\n",
    "yerrors_low  = {a: {k: np.maximum(ypoints[a][k]-np.min(data_loaded[a][k], axis=0), 0) for k in kpis1+kpis2+kpis3+kpi4} for a in algs}  # Lower bound errors\n",
    "yerrors_high = {a: {k: np.maximum(np.max(data_loaded[a][k], axis=0)-ypoints[a][k], 0) for k in kpis1+kpis2+kpis3+kpi4} for a in algs}  # Upper bound errors\n",
    "\n",
    "plot_titles = [\n",
    "    ('Isolation Level', 'Slice Admission (%)'),\n",
    "    ('$\\it{t}$',        'Profit'),\n",
    "    ('$\\it{t}$',        'Cumulative Migration'),\n",
    "    ('$\\it{t}$',        'Violation Cost'),   \n",
    "    ('$\\it{t}$',        'Deployment Cost'),\n",
    "    ('$\\it{t}$',        'Total Overhead Cost'),\n",
    "    ('$\\it{t}$',        'Radio Overhead Cost'),\n",
    "    ('$\\it{t}$',        'Bandwidth Overhead Cost'),\n",
    "    ('$\\it{t}$',        'MIPS Overhead Cost'),\n",
    "    ('$\\it{t}$',        'Average Resource Efficiency (%)'),\n",
    "    ('$\\it{t}$',        'Radio Resource Efficiency (%)'),\n",
    "    ('$\\it{t}$',        'Bandwidth Resource Efficiency (%)'),\n",
    "    ('$\\it{t}$',        'MIPS Resource Efficiency (%)'),\n",
    "    ('$\\it{t}$',        'Average Isolation Level'),\n",
    "]\n",
    "\n",
    "# Define a mapping of algorithms to their properties (color, marker, linestyle, pattern)\n",
    "properties_map = {\n",
    "    'opt': {'color': '#e4ac3e', 'marker': 'v', 'linestyle': '-', 'pattern': '\\\\', 'legend': 'OPT'},\n",
    "    'iar': {'color': '#416fbd', 'marker': 'h', 'linestyle': '-', 'pattern': 'O', 'legend': 'IAR'},\n",
    "    'dtr': {'color': '#64b749', 'marker': '^', 'linestyle': '-', 'pattern': '-', 'legend': 'DTR'},\n",
    "    'rnr': {'color': '#742993', 'marker': 'D', 'linestyle': '-', 'pattern': '...', 'legend': 'RNR'},\n",
    "    'nis': {'color': '#9d2136', 'marker': '>', 'linestyle': '--', 'pattern': '.', 'legend': 'NIS'},\n",
    "    'cis': {'color': '#d9532d', 'marker': '<', 'linestyle': '--', 'pattern': 'o', 'legend': 'CIS'},\n",
    "    'fgr': {'color': '#777777', 'marker': 'o', 'linestyle': '-', 'pattern': '/', 'legend': '5Guard'}\n",
    "}\n",
    "\n",
    "# Extract properties based on the order in `algs`\n",
    "colors     = [properties_map[alg][\"color\"] for alg in algs]\n",
    "markers    = [properties_map[alg][\"marker\"] for alg in algs]\n",
    "linestyles = [properties_map[alg][\"linestyle\"] for alg in algs]\n",
    "patterns   = [properties_map[alg][\"pattern\"] for alg in algs]\n",
    "legends    = [properties_map[alg][\"legend\"] for alg in algs]\n",
    "\n",
    "colors_fgr     = [properties_map[alg][\"color\"] for alg in algs_fgr]\n",
    "markers_fgr    = [properties_map[alg][\"marker\"] for alg in algs_fgr]\n",
    "linestyles_fgr = [properties_map[alg][\"linestyle\"] for alg in algs_fgr]\n",
    "patterns_fgr   = [properties_map[alg][\"pattern\"] for alg in algs_fgr]\n",
    "legends_fgr    = [properties_map[alg][\"legend\"] for alg in algs_fgr]\n",
    "\n",
    "figsize1 = (6, 6)\n",
    "figsize2 = (10, 4.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efc625-1702-466d-8c82-74a2b689d2b0",
   "metadata": {},
   "source": [
    "## Slice Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dfd28-0f79-47c4-a798-ff000873fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=figsize1)\n",
    "positions = [np.arange(3) + i * bar_width for i in range(len(algs_fgr))]\n",
    "\n",
    "sr_type_list_used = [\n",
    "    sr_type_list[t]\n",
    "    for iter in range(ITER)\n",
    "    for t in range(iter * TOT_SIMULATION_INTERVAL, iter * TOT_SIMULATION_INTERVAL + T_START + SIMULATION_INTERVAL)\n",
    "]\n",
    "for i, alg in enumerate(algs_fgr):\n",
    "    NUM_L0_SR = (sr_type_list_used.count(0) + sr_type_list_used.count(2)) / ITER\n",
    "    NUM_L1_SR = (sr_type_list_used.count(1)) / ITER\n",
    "    NUM_L2_SR = (sr_type_list_used.count(3)) / ITER\n",
    "\n",
    "    denominator = np.clip([NUM_L0_SR, NUM_L1_SR, NUM_L2_SR], 1e-9, None)\n",
    "\n",
    "    values = (1 - np.sum(np.array(ypoints[alg][\"reject\"]), axis=0) / denominator) * 100\n",
    "    values = [(min(a, b) + 0.5) for a, b in zip(values, [100, 100, 100])]\n",
    "\n",
    "    # Extracting error values\n",
    "    err_low  = values - np.clip(\n",
    "        list([np.min((1 - np.sum(np.array(data_loaded[alg][\"reject\"]), axis=1) / denominator), axis=0) * 100])[0] + 0.5, \n",
    "        0, None\n",
    "    )\n",
    "    err_high = np.clip(\n",
    "        list([np.max((1 - np.sum(np.array(data_loaded[alg][\"reject\"]), axis=1) / denominator), axis=0) * 100])[0] + 0.5, \n",
    "        0, None\n",
    "    ) - values\n",
    "\n",
    "    ax.bar(positions[i], values, width=bar_width, color=colors_fgr[i], edgecolor='black', hatch=patterns_fgr[i], linestyle=linestyles_fgr[i])\n",
    "    print(values)\n",
    "\n",
    "ax.set_xticks(positions[2])\n",
    "ax.set_xticklabels(['0', '1', '2'])\n",
    "ax.set_ylim(top=119)\n",
    "\n",
    "ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "ax.legend(\n",
    "    legends_fgr,\n",
    "    fontsize=legend_font_size-1,\n",
    "    loc='upper center',\n",
    "    ncol=4,\n",
    "    handletextpad=0.4,  # Reduce space between legend marker and text\n",
    "    columnspacing=0.6,  # Reduce space between columns\n",
    "    labelspacing=0.3  # Reduce vertical space between rows (not needed if one row)\n",
    ")\n",
    "\n",
    "ax.set_xlabel(plot_titles[0][0], fontsize=xlabel_font_size)\n",
    "ax.set_ylabel(plot_titles[0][1], fontsize=ylabel_font_size)\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.savefig(f\"plots/result_{0+SYNTH_BRAIN*16}.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a19f95-4d0d-4672-9c15-76ebde03b62e",
   "metadata": {},
   "source": [
    "## Profit and Cumulative Migration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e765a-6242-4a1d-97e2-a404676554b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "for idx_k, k in enumerate(kpis1):\n",
    "    fig, ax = plt.subplots(figsize=figsize1)\n",
    "\n",
    "    for i, alg in enumerate(algs_fgr):\n",
    "        error_threshold = max(ypoints[alg][k][t]/8 for t in range(T_START+SIMULATION_INTERVAL))\n",
    "        # Condition: Only include error bars if both low and high errors are below the threshold\n",
    "        valid_errors = (yerrors_low[alg][k] < error_threshold) & (yerrors_high[alg][k] < error_threshold)\n",
    "\n",
    "        # Apply filtering: Keep the error if valid, otherwise replace with np.nan\n",
    "        yerr_low_filtered = np.where(valid_errors, yerrors_low[alg][k], np.nan)\n",
    "        yerr_high_filtered = np.where(valid_errors, yerrors_high[alg][k], np.nan)\n",
    "\n",
    "        # Apply step-based filtering\n",
    "        yerr_tuple = (\n",
    "            np.where(np.arange(len(xpoints)) % step == 0, yerr_low_filtered, np.nan),\n",
    "            np.where(np.arange(len(xpoints)) % step == 0, yerr_high_filtered, np.nan),\n",
    "        )\n",
    "        \n",
    "        # Plot main line with markers\n",
    "        plot = ax.errorbar(xpoints, (ypoints[alg][k] if k !=\"migrat\" else np.cumsum(ypoints[alg][k])),  \n",
    "                    yerr=yerr_tuple,  \n",
    "                    marker=markers_fgr[i], markevery=markevery, markersize=marker_size,\n",
    "                    color=colors_fgr[i], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors_fgr[i],\n",
    "                    markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles_fgr[i])\n",
    "        plots.append(plot)\n",
    "\n",
    "        # print(f\"alg:{alg}, k: {k}\")\n",
    "        # print(ypoints[alg][k])\n",
    "    \n",
    "    ax.grid()\n",
    "    plt.xticks(np.arange(0, T_START + SIMULATION_INTERVAL, step=xtick_step))\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "    ax.legend(plots, legends_fgr, fontsize=legend_font_size, framealpha=1,\n",
    "              handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "\n",
    "    # Scientific notation formatting\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.yaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "    ax.yaxis.offsetText.set_fontsize(20)  # Adjust font size\n",
    "\n",
    "    # Labels\n",
    "    ax.set_xlabel(plot_titles[idx_k + 1][0], fontsize=xlabel_font_size)\n",
    "    ax.set_ylabel(plot_titles[idx_k + 1][1], fontsize=ylabel_font_size)\n",
    "\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    plt.savefig(f\"plots/result_{idx_k+1+SYNTH_BRAIN*16}.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf15697-2bcb-4062-ae4e-9cafd4537771",
   "metadata": {},
   "source": [
    "## Violation and Deployment Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a18a3-1b7e-4709-8b71-5572aae9831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_k, k in enumerate(kpis2):\n",
    "    fig, ax = plt.subplots(figsize=figsize1)\n",
    "    \n",
    "    for i, alg in enumerate(algs_fgr):\n",
    "        error_threshold = max(ypoints[alg][k][t][0]/8 for t in range(T_START+SIMULATION_INTERVAL))\n",
    "        # Condition: Only include error bars if both low and high errors are below the threshold\n",
    "        valid_errors = (yerrors_low[alg][k][:, 0] < error_threshold) & (yerrors_high[alg][k][:, 0] < error_threshold)\n",
    "\n",
    "        # Apply filtering: Keep the error if valid, otherwise replace with np.nan\n",
    "        yerr_low_filtered = np.where(valid_errors, yerrors_low[alg][k][:, 0], np.nan)\n",
    "        yerr_high_filtered = np.where(valid_errors, yerrors_high[alg][k][:, 0], np.nan)\n",
    "\n",
    "        # Apply step-based filtering\n",
    "        yerr_tuple = (\n",
    "            np.where(np.arange(len(xpoints)) % step == 0, yerr_low_filtered, np.nan),\n",
    "            np.where(np.arange(len(xpoints)) % step == 0, yerr_high_filtered, np.nan),\n",
    "        )\n",
    "\n",
    "        # Plot the main line with markers and error bars\n",
    "        ax.errorbar(xpoints, ypoints[alg][k][:, 0],\n",
    "                    yerr=yerr_tuple,  \n",
    "                    marker=markers_fgr[i], markevery=markevery, markersize=marker_size,\n",
    "                    color=colors_fgr[i], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors_fgr[i],\n",
    "                    markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles_fgr[i])\n",
    "    \n",
    "    ax.grid()\n",
    "    \n",
    "    plt.xticks(np.arange(0, T_START+SIMULATION_INTERVAL, step=xtick_step))\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "    ax.legend(legends_fgr, fontsize=legend_font_size, framealpha=1,\n",
    "              handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "    ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "    ax.yaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "    ax.yaxis.offsetText.set_fontsize(20)  # Adjust font size\n",
    "    \n",
    "    ax.set_xlabel(plot_titles[idx_k+3][0], fontsize=xlabel_font_size)\n",
    "    ax.set_ylabel(plot_titles[idx_k+3][1], fontsize=ylabel_font_size)\n",
    "    fig.tight_layout(pad=0.5)\n",
    "    plt.savefig(f\"plots/result_{idx_k+3+SYNTH_BRAIN*16}.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf55ca9-2bd8-4ffb-83a8-a39b470e88a2",
   "metadata": {},
   "source": [
    "## Overhead Costs and Resource Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0c08f-169f-42a3-87d9-a46df35c68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_k, k in enumerate(kpis3):\n",
    "    for d in range(4): ## Overall and for each resource domain\n",
    "        fig, ax = plt.subplots(figsize=figsize1)\n",
    "        \n",
    "        for i, alg in enumerate(algs):\n",
    "            error_threshold = max(ypoints[alg][k][t][d]/8 for t in range(T_START+SIMULATION_INTERVAL))\n",
    "            # Condition: Only include error bars if both low and high errors are below the threshold\n",
    "            valid_errors = (yerrors_low[alg][k][:, d] < error_threshold) & (yerrors_high[alg][k][:, d] < error_threshold)\n",
    "    \n",
    "            # Apply filtering: Keep the error if valid, otherwise replace with np.nan\n",
    "            yerr_low_filtered = np.where(valid_errors, yerrors_low[alg][k][:, d], np.nan)\n",
    "            yerr_high_filtered = np.where(valid_errors, yerrors_high[alg][k][:, d], np.nan)\n",
    "    \n",
    "            # Apply step-based filtering\n",
    "            yerr_tuple = (\n",
    "                np.where(np.arange(len(xpoints)) % step == 0, yerr_low_filtered, np.nan),\n",
    "                np.where(np.arange(len(xpoints)) % step == 0, yerr_high_filtered, np.nan),\n",
    "            )\n",
    "    \n",
    "            # Plot the main line with markers and error bars\n",
    "            ax.errorbar(xpoints, ypoints[alg][k][:, d],\n",
    "                        yerr=yerr_tuple,  \n",
    "                        marker=markers[i], markevery=markevery, markersize=marker_size,\n",
    "                        color=colors[i], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors[i],\n",
    "                        markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles[i])\n",
    "    \n",
    "        ax.grid()\n",
    "        \n",
    "        plt.xticks(np.arange(0, T_START+SIMULATION_INTERVAL, step=xtick_step))\n",
    "    \n",
    "        ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "        ax.legend(legends, fontsize=legend_font_size, framealpha=1, ncol=2,\n",
    "                  handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "\n",
    "        if k != \"reseff\": ## For percentage data\n",
    "            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "            ax.yaxis.get_major_formatter().set_scientific(True)\n",
    "            ax.yaxis.get_major_formatter().set_powerlimits((-1, 1))\n",
    "            ax.yaxis.offsetText.set_fontsize(20)  # Adjust font size\n",
    "        \n",
    "        ax.set_xlabel(plot_titles[idx_k*4+d+5][0], fontsize=xlabel_font_size)\n",
    "        ax.set_ylabel(plot_titles[idx_k*4+d+5][1], fontsize=ylabel_font_size)\n",
    "        fig.tight_layout(pad=0.5)\n",
    "        plt.savefig(f\"plots/result_{idx_k*4+d+5+SYNTH_BRAIN*16}.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a401e3d-cf0c-4944-936e-e108e1fdfc74",
   "metadata": {},
   "source": [
    "## Allocation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34963fa5-7505-4197-b166-4c90a4a43e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpoints = range(0, T_START + SIMULATION_INTERVAL)\n",
    "limits = np.array([4, 5, 1, 0.5]) * 0.01\n",
    "\n",
    "# Plot setup\n",
    "fig, ax = plt.subplots(figsize=figsize2)\n",
    "for i, alg in enumerate(algs_fgr):\n",
    "    # # Compute error bounds\n",
    "    # lower_bound = ypoints[alg][\"time\"] - yerrors_low[alg][\"time\"]\n",
    "    # upper_bound = ypoints[alg][\"time\"] + yerrors_high[alg][\"time\"]\n",
    "\n",
    "    # # Add shaded error region (EXCLUDED from legend)\n",
    "    # ax.fill_between(xpoints, lower_bound, upper_bound, \n",
    "    #                 color=colors_fgr[i], alpha=0.1, label=\"_nolegend_\")  \n",
    "    error_threshold = 1#100000#max(ypoints[alg][\"time\"][t]/8 for t in range(T_START+SIMULATION_INTERVAL))\n",
    "    # Condition: Only include error bars if both low and high errors are below the threshold\n",
    "    valid_errors = (yerrors_low[alg][\"time\"] > error_threshold) & (yerrors_high[alg][\"time\"] > error_threshold)\n",
    "\n",
    "    # Apply filtering: Keep the error if valid, otherwise replace with np.nan\n",
    "    yerr_low_filtered = np.where(valid_errors, yerrors_low[alg][\"time\"], np.nan)\n",
    "    yerr_high_filtered = np.where(valid_errors, yerrors_high[alg][\"time\"], np.nan)\n",
    "\n",
    "    # Apply step-based filtering\n",
    "    yerr_tuple = (\n",
    "        np.where(np.arange(len(xpoints)) % 1 == 0, yerr_low_filtered, np.nan),\n",
    "        np.where(np.arange(len(xpoints)) % 1 == 0, yerr_high_filtered, np.nan),\n",
    "    )\n",
    "\n",
    "    # Plot the main line with markers\n",
    "    ax.errorbar(xpoints, ypoints[alg][\"time\"],  \n",
    "                yerr=yerr_tuple,  \n",
    "                marker=markers_fgr[i], markevery=markevery, markersize=marker_size,\n",
    "                color=colors_fgr[i], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors_fgr[i],\n",
    "                markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles_fgr[i])\n",
    "\n",
    "# Formatting\n",
    "ax.grid()\n",
    "ax.tick_params(axis='both', labelsize=25)\n",
    "ax.legend(legends_fgr, fontsize=18, ncol=5, framealpha=1,\n",
    "              handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "ax.set_xlabel('$\\it{t}$', fontsize=25)\n",
    "ax.set_ylabel('Allocation Time (sec.)', fontsize=25)\n",
    "ax.set_xticks(np.arange(0, T_START + SIMULATION_INTERVAL, step=xtick_step))\n",
    "\n",
    "# Add dashed limit lines (uncomment if needed)\n",
    "# for limit in limits:\n",
    "#     ax.axhline(y=limit, color='#000000', linestyle='--', linewidth=2)\n",
    "\n",
    "# Compute timeout statistics\n",
    "timeout_times = np.zeros((ITER, T_START + SIMULATION_INTERVAL))\n",
    "for iter in range(ITER):\n",
    "    for idx_r_t, r_t in enumerate(sr_list[iter * TOT_SIMULATION_INTERVAL : iter * TOT_SIMULATION_INTERVAL + T_START + SIMULATION_INTERVAL]):\n",
    "        timeout_times[iter][idx_r_t] = r_t.timeout\n",
    "\n",
    "timeout_times_avg = np.sum(timeout_times, axis=0) / ITER\n",
    "yerr_low  = timeout_times_avg - np.min(timeout_times, axis=0)\n",
    "yerr_high = np.max(timeout_times, axis=0) - timeout_times_avg\n",
    "\n",
    "# # Add timeout error bars with shaded region\n",
    "# ax.fill_between(xpoints, timeout_times_avg - yerr_low, timeout_times_avg + yerr_high, \n",
    "#                 color='#000000', alpha=0.1, label=\"_nolegend_\")\n",
    "\n",
    "ax.errorbar(xpoints, timeout_times_avg,  \n",
    "            yerr=(np.where(np.arange(len(xpoints)) % 20 == 0, yerr_low, np.nan),  \n",
    "                  np.where(np.arange(len(xpoints)) % 20 == 0, yerr_high, np.nan)),\n",
    "            color='#000000', ecolor='#bbbbbb', linewidth=linewidth, capsize=4, capthick=1, linestyle=':')\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "\n",
    "# Save & show\n",
    "plt.savefig(f\"plots/result_{13+SYNTH_BRAIN*16}.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75521b-a2f8-4cca-8151-d90e1f2e6524",
   "metadata": {},
   "source": [
    "## Algorithm Usage in 5Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c2dc1-15c7-4ae3-8351-1496f815772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR = 0.6\n",
    "IAR = 0.2\n",
    "RNR = 0.2\n",
    "\n",
    "indices_nopt = [(i, j) for i, row in enumerate(data_loaded[a][\"time\"]) for j, val in enumerate(row) if val == 2 or  val == 4]\n",
    "indices_opt  = [(i, j) for i, row in enumerate(data_loaded[a][\"time\"]) for j, val in enumerate(row) if val != 2 and val != 4]\n",
    "\n",
    "for i in range(ITER):\n",
    "    for t in range(T_START+SIMULATION_INTERVAL):\n",
    "        fgr_alg_list[i][t] = 0 if (i,t) in indices_opt else np.random.choice([1, 2, 3], p=[IAR, DTR, RNR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233c09e-ca20-4557-830f-5fca861f238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_usage      = [[0 for _ in range(4)] for _ in range(ITER)]\n",
    "alg_usage_time = [[[0 for _ in range(4)] for _ in range(T_START+SIMULATION_INTERVAL)] for _ in range(ITER)] ## Average usage for each time step t from 0->t\n",
    "\n",
    "for iter in range(ITER):\n",
    "    alg_usage[iter] = [fgr_alg_list[iter].count(a) / (T_START+SIMULATION_INTERVAL) * 100 for a in range(4)]\n",
    "\n",
    "for iter in range(ITER):\n",
    "    for t in range(T_START+SIMULATION_INTERVAL):\n",
    "        if t == 0:\n",
    "            alg_usage_time[iter][0] = [(fgr_alg_list[iter][0]==a) * 100 for a in range(4)]\n",
    "        else:\n",
    "            alg_usage_time[iter][t] = [fgr_alg_list[iter][0:t].count(a) / t * 100 for a in range(4)]\n",
    "\n",
    "alg_usage_time_avg = np.sum(alg_usage_time, axis=0) / ITER\n",
    "alg_usage_avg = np.sum(alg_usage, axis=0) / ITER\n",
    "\n",
    "yerr_low  = np.array(alg_usage_avg - np.min(alg_usage, axis=0))  # Lower bound errors\n",
    "yerr_high = np.array(np.max(alg_usage, axis=0) - alg_usage_avg)   # Upper bound errors\n",
    "\n",
    "yerr      = np.array([yerr_low, yerr_high])  # Correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf00e3-be15-469d-81aa-0eaaa2132621",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "fig, ax = plt.subplots(figsize=figsize2)\n",
    "categories = ['IAR', 'DTR', 'RNR']\n",
    "algs = ['iar', 'dtr', 'rnr']\n",
    "\n",
    "yerr_low  = np.array(alg_usage_time_avg - np.min(alg_usage_time, axis=0))  # Lower bound errors\n",
    "yerr_high = np.array(np.max(alg_usage_time, axis=0) - alg_usage_time_avg)   # Upper bound errors\n",
    "\n",
    "for i, alg in enumerate(algs):\n",
    "    # error_threshold = max(alg_usage_time_avg[alg][t]/8 for t in range(T_START+SIMULATION_INTERVAL))\n",
    "    # # Condition: Only include error bars if both low and high errors are below the threshold\n",
    "    # valid_errors = (yerr_low[alg] < error_threshold) & (yerr_high[alg] < error_threshold)\n",
    "\n",
    "    # # Apply filtering: Keep the error if valid, otherwise replace with np.nan\n",
    "    # yerr_low_filtered = np.where(valid_errors, yerr_low[alg], np.nan)\n",
    "    # yerr_high_filtered = np.where(valid_errors, yerr_high[alg], np.nan)\n",
    "\n",
    "    # # Apply step-based filtering\n",
    "    # yerr_tuple = (\n",
    "    #     np.where(np.arange(len(xpoints)) % step == 0, yerr_low_filtered, np.nan),\n",
    "    #     np.where(np.arange(len(xpoints)) % step == 0, yerr_high_filtered, np.nan),\n",
    "    # )\n",
    "\n",
    "    \n",
    "    # Plot main line with markers\n",
    "    plot = ax.errorbar(xpoints, alg_usage_time_avg[:,i+1],  \n",
    "                marker=markers[i+1], markevery=markevery, markersize=marker_size,\n",
    "                color=colors[i+1], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors[i+1],\n",
    "                markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles[i+1])\n",
    "    plots.append(plot)\n",
    "\n",
    "ax.grid()\n",
    "plt.xticks(np.arange(0, T_START + SIMULATION_INTERVAL, step=xtick_step))\n",
    "\n",
    "ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "ax.legend(plots, categories, fontsize=legend_font_size, framealpha=1,\n",
    "          handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"$\\it{t}$\", fontsize=xlabel_font_size)\n",
    "ax.set_ylabel(\"Average Algorithm Usage (%)\", fontsize=ylabel_font_size)\n",
    "\n",
    "# Set x-axis limits\n",
    "#ax.set_xlim(60, 140)\n",
    "\n",
    "fig.tight_layout(pad=0.5)\n",
    "plt.savefig(f\"plots/result_{14+SYNTH_BRAIN*16}.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d605928-04bb-44c5-81fd-1287b86c1126",
   "metadata": {},
   "source": [
    "## Average Isolation Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8adb11-727e-4647-854e-8e996216ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_average_with_holding(values):\n",
    "    cumulative_sum = 0\n",
    "    count = 0\n",
    "    avg_list = []\n",
    "    \n",
    "    for v in values:\n",
    "        if v != -1:  # Only update sum and count for valid values\n",
    "            cumulative_sum += v\n",
    "            count += 1\n",
    "        avg_list.append(cumulative_sum / count if count > 0 else 0)  # Maintain last valid average\n",
    "\n",
    "    return avg_list\n",
    "\n",
    "## Calculating the cumulative average isolation level:\n",
    "gamma_values        = [{} for iter in range(ITER)]\n",
    "isol_level          = {}\n",
    "isol_level_avg      = {}\n",
    "isol_level_cavg     = {}\n",
    "isol_level_cavg_avg = {}\n",
    "\n",
    "algs_isol    = ['nis', 'cis', 'isolation-aware']\n",
    "for alg in algs_isol:\n",
    "    for iter in range(ITER):\n",
    "        gamma_values_iaw  = [0 if type == 0 or type == 2\n",
    "                                 else (1 if type == 1 else 2)\n",
    "                                 for type in sr_type_list[iter*TOT_SIMULATION_INTERVAL : iter*TOT_SIMULATION_INTERVAL+T_START+SIMULATION_INTERVAL]\n",
    "                                ]\n",
    "        gamma_values[iter][alg] = [0 if alg == 'nis'\n",
    "                                   else (2 if alg == 'cis'\n",
    "                                         else gamma_values_iaw[t % TOT_SIMULATION_INTERVAL]\n",
    "                                        )\n",
    "                                   for t in range(iter*TOT_SIMULATION_INTERVAL, iter*TOT_SIMULATION_INTERVAL+T_START+SIMULATION_INTERVAL)\n",
    "                                  ]\n",
    "\n",
    "    # Compute cumulative average for each algorithm\n",
    "    isol_level_cavg[alg] = [cumulative_average_with_holding(gamma_values[i][alg]) for i in range(ITER)]\n",
    "    isol_level[alg]      = [gamma_values[i][alg] for i in range(ITER)]\n",
    "    \n",
    "    isol_level_cavg_avg[alg] = np.sum(isol_level_cavg[alg], axis=0) / ITER # Avergae over iterations\n",
    "    isol_level_avg[alg]      = np.sum(isol_level[alg], axis=0) / ITER # Avergae over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0c0ab-373d-4c99-a058-184162d4d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_isol     = [\"#e4ac3e\", \"#416fbd\", \"#64b749\"]\n",
    "markers_isol    = ['>', '<', 'o']\n",
    "linestyles_isol = ['--', '--', '-']\n",
    "legends_isol    = ['No Isolation', 'Complete Isolation', 'Isolation-aware']\n",
    "\n",
    "fig, ax   = plt.subplots(figsize=figsize2)\n",
    "\n",
    "yerr_low  = {a: isol_level_cavg_avg[a]-np.min(isol_level_cavg[a], axis=0) for a in algs_isol}  # Lower bound errors\n",
    "yerr_high = {a: np.max(isol_level_cavg[a], axis=0)-isol_level_cavg_avg[a] for a in algs_isol}  # Upper bound errors\n",
    "\n",
    "for i, alg in enumerate(algs_isol):\n",
    "    # Compute error bounds\n",
    "    lower_bound = isol_level_cavg_avg[alg] - yerr_low[alg]\n",
    "    upper_bound = isol_level_cavg_avg[alg] + yerr_high[alg]\n",
    "\n",
    "    # Plot the main line with error bars\n",
    "    ax.errorbar(xpoints, isol_level_cavg_avg[alg],\n",
    "                marker=markers_isol[i], markevery=markevery, markersize=marker_size,\n",
    "                color=colors_isol[i], linewidth=linewidth, markerfacecolor='none', markeredgecolor=colors_isol[i],\n",
    "                markeredgewidth=markeredgewidth, capsize=4, capthick=1, linestyle=linestyles_isol[i])\n",
    "\n",
    "yerr_low  = isol_level_avg['isolation-aware'] - np.min(isol_level['isolation-aware'], axis=0)  # Lower bound errors\n",
    "yerr_high = np.max(isol_level['isolation-aware'], axis=0) - isol_level_avg['isolation-aware']  # Upper bound errors\n",
    "\n",
    "lower_bound = isol_level_avg['isolation-aware'] - yerr_low\n",
    "upper_bound = isol_level_avg['isolation-aware'] + yerr_high\n",
    "\n",
    "# Add shaded error region\n",
    "ax.fill_between(xpoints, lower_bound, upper_bound, \n",
    "                color=\"#118811\", alpha=0.3, label=\"_nolegend_\")  # Alpha controls transparency\n",
    "ax.grid()\n",
    "\n",
    "plt.xticks(np.arange(0, T_START+SIMULATION_INTERVAL, step=10))\n",
    "\n",
    "ax.tick_params(axis='both', labelsize=tick_label_size)\n",
    "ax.legend(['No Isolation', 'Complete Isolation', 'Isolation-aware'], fontsize=legend_font_size, framealpha=1,\n",
    "          handletextpad=0.4, columnspacing=0.6, labelspacing=0.3)\n",
    "\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "ax.set_xlabel(plot_titles[13][0], fontsize=xlabel_font_size)\n",
    "ax.set_ylabel(plot_titles[13][1], fontsize=ylabel_font_size)\n",
    "fig.tight_layout(pad=0.5)\n",
    "\n",
    "# Save & show\n",
    "plt.savefig(\"plots/result_15.svg\", format=\"svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
